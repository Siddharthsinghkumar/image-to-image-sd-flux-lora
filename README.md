# Image-to-Image Generation with Stable Diffusion & Flux 1 Dev

> A local, self-hosted pipeline for advanced image-to-image transformations  
> using Stable Diffusion (AUTOMATIC1111 WebUI) and Flux 1 Dev extensions.  
> Focused on realism evaluation, texture reconstruction, and anatomy-preserving edits via LoRA models.

---

## ğŸ§  Project Objective

This repository is a **technical exploration of how diffusion models handle fine-grained image editing tasks**, specifically:

- Reconstructing textures (e.g., skin, fabric) under prompt control  
- Preserving facial identity and body pose consistency  
- Tuning LoRA weight blends for style fidelity

By running everything locally, we avoid cloud dependencies and gain precise control over GPU memory, sampling, and prompt/seed configurations.

---

## ğŸ§° Tech Stack & Tools

- **Stable Diffusion WebUI** by AUTOMATIC1111  
- **Flux 1 Dev** extension  
- Custom `.ckpt` and LoRA (`.safetensors`) model files  
- Python 3.10+, PyTorch, xformers, diffusers

> âš™ï¸ **Tested on:**  
> â€¢ Ubuntu 22.04 LTS  
> â€¢ NVIDIA RTX 3050 Ti (4 GB VRAM)  
> â€¢ 16 GB RAM (with 32 GB swap)  

---

## ğŸ” Key Features

- âœ… Local GPU-powered inference (no cloud required)  
- âœ… Image-to-image with adjustable strength, CFG scale, denoise, and sampler  
- âœ… LoRA blending for controlled style transfers  
- âœ… Prompt weighting and seed reproducibility  
- âœ… VRAM optimization (`--medvram`, attention slicing, CPU offload)

---

## ğŸ–¼ Example Workflow

```bash
# 1. Clone this repo
git clone https://github.com/<your-username>/img2img-sd-flux-custom.git
cd img2img-sd-flux-custom

# 2. Drop custom models into ./models/
#    e.g., models/flux1-dev.safetensors, models/my-lora.safetensors

# 3. Launch AUTOMATIC1111â€™s WebUI (inside a virtual environment):
cd ~/stable-diffusion-webui
python launch.py --xformers --medvram --opt-sub-quad-attention

# 4. In the WebUIâ€™s â€œimg2imgâ€ tab:
#    â€¢ Upload ./images/input.jpg  
#    â€¢ Select your LoRA (e.g., â€œmy-loraâ€) and adjust strength (0.3â€“0.7)  
#    â€¢ Tweak CFG (5â€“11), steps (50â€“100), sampler (Euler a, DDIM, etc.)  
#    â€¢ Click â€œGenerateâ€ â†’ save to ./images/output.jpg  

# 5. Compare side-by-side (assets/before-after.png)
```

---

## ğŸ—‚ Folder Structure

```
img2img-sd-flux-custom/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt         # (if using extra Python scripts)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ flux1-dev.safetensors
â”‚   â””â”€â”€ my-lora.safetensors
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ input.jpg
â”‚   â””â”€â”€ output.jpg
â”œâ”€â”€ config/
â”‚   â””â”€â”€ img2img-settings.json
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ launch_notes.md
â””â”€â”€ assets/
    â””â”€â”€ before-after.png
```

---

## ğŸ’¡ Applications / Skills Demonstrated

| Category                | Details                                                         |
|-------------------------|-----------------------------------------------------------------|
| ğŸ§  Prompt Engineering   | Prompt weighting, seed control, sampler choice, CFG tuning       |
| ğŸ›  VRAM Optimization     | `--medvram`, attention slicing, CPU offload                      |
| ğŸ¨ Style Control         | LoRA blending (e.g., â€œmy-lora.safetensorsâ€ for style fidelity)   |
| ğŸ“Š Realism Benchmarking  | Before/after comparisons, image fidelity metrics, texture checks |

---

## âš ï¸ Disclaimer

> This project uses open-domain models capable of sensitive content.  
> All testing is **local** and for **technical evaluation only**.  
> No explicit or disallowed content is shared. Intended for AI development and research.

---

## ğŸ“¬ Contributing / Contact

Feel free to [open an issue](https://github.com/<your-username>/img2img-sd-flux-custom/issues) or submit a pull request.  
**Author**: `<Siddharthsinghkumar>`  
**Repo:** [img2img-sd-flux-custom](https://github.com/<your-username>/img2img-sd-flux-custom)
